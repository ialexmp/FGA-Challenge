{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Face and Gestures Analysis: Face Identification Challenge\n",
    "\n",
    "Students:\n",
    "* Manuel Parma (255570)\n",
    "* Àlex Montoya (242873)\n",
    "* Marina Riba (229240)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# from imageio import imread\n",
    "from imageio.v2 import imread\n",
    "from scipy.io import loadmat\n",
    "import random\n",
    "import time\n",
    "import itertools"
   ],
   "metadata": {
    "id": "zs_xu1Vt3cXK",
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:08.268674Z",
     "start_time": "2024-02-29T19:14:08.006404Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions"
   ],
   "metadata": {
    "id": "knV8wBCG1riw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def CHALL_AGC_ComputeRecognScores(auto_ids, true_ids):\n",
    "    #   Compute face recognition score\n",
    "    #\n",
    "    #   INPUTS\n",
    "    #     - AutomSTR: The results of the automatic face\n",
    "    #     recognition algorithm, stored as an integer\n",
    "    #\n",
    "    #     - AGC_Challenge_STR: The ground truth ids\n",
    "    #\n",
    "    #   OUTPUT\n",
    "    #     - FR_score:     The final recognition score\n",
    "    #\n",
    "    #   --------------------------------------------------------------------\n",
    "    #   AGC Challenge\n",
    "    #   Universitat Pompeu Fabra\n",
    "    #\n",
    "\n",
    "    if len(auto_ids) != len(true_ids):\n",
    "        assert ('Inputs must be of the same len');\n",
    "\n",
    "    f_beta = 1\n",
    "    res_list = list(filter(lambda x: true_ids[x] != -1, range(len(true_ids))))\n",
    "\n",
    "    nTP = len([i for i in res_list if auto_ids[i] == true_ids[i]])\n",
    "\n",
    "    res_list = list(filter(lambda x: auto_ids[x] != -1, range(len(auto_ids))))\n",
    "\n",
    "    nFP = len([i for i in res_list if auto_ids[i] != true_ids[i]])\n",
    "\n",
    "    res_list_auto_ids = list(filter(lambda x: auto_ids[x] == -1, range(len(auto_ids))))\n",
    "    res_list_true_ids = list(filter(lambda x: true_ids[x] != -1, range(len(true_ids))))\n",
    "\n",
    "    nFN = len(set(res_list_auto_ids).intersection(res_list_true_ids))\n",
    "\n",
    "    FR_score = (1 + f_beta ** 2) * nTP / ((1 + f_beta ** 2) * nTP + f_beta ** 2 * nFN + nFP)\n",
    "\n",
    "    return FR_score"
   ],
   "metadata": {
    "id": "YLCkyFMv1mR5",
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:08.289128Z",
     "start_time": "2024-02-29T19:14:08.276089Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tf\n",
    "from PIL import Image\n",
    "import pickle\n"
   ],
   "metadata": {
    "id": "oog2lybvxzUy",
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:10.259287Z",
     "start_time": "2024-02-29T19:14:08.291665Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# face recognition code\n",
    "classifier_file = os.path.dirname(cv.__file__) + \"/data/haarcascade_frontalface_alt.xml\"\n",
    "face_cascade = cv.CascadeClassifier(classifier_file)\n",
    "\n",
    "def face_detection(img, scaleFactor=1.1, minNeighbors=6, minSize=[100, 100]):\n",
    "    \"\"\"\n",
    "    Method for detecting faces in an image using the Viola-Jones algorithm.\n",
    "    :param img: Image data to detect the faces on.\n",
    "    :return: Cropped image on face, None if no face is detected\n",
    "    \"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "      # convert to grey image\n",
    "      gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "      gray_image = img\n",
    "\n",
    "    # we run multiple tests for the three parameters and got the best performance\n",
    "    # (approx. 85% accuracy) with these values.\n",
    "    faces = face_cascade.detectMultiScale(gray_image,\n",
    "                                          scaleFactor=scaleFactor,\n",
    "                                          minNeighbors=minNeighbors,\n",
    "                                          minSize=minSize)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "      return None\n",
    "\n",
    "    # we keep the biggest bounding box\n",
    "    if len(faces) > 1:\n",
    "        faces = sorted(faces, key=lambda rect: rect[2] * rect[3], reverse=True)\n",
    "        faces = faces[:1]\n",
    "\n",
    "    # convert to coordinates\n",
    "    x, y, w, h = faces[0]\n",
    "    return img[y:y+h, x:x+w]"
   ],
   "metadata": {
    "id": "xsFfcT0VxIVA",
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:10.280448Z",
     "start_time": "2024-02-29T19:14:10.261377Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class VGGSimple5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "\n",
    "        super(VGGSimple5, self).__init__()\n",
    "\n",
    "        self.conv11 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv13 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv20 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv21 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv22 = nn.Conv2d(128,128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=5, stride=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(8*8*128, 80)\n",
    "        self.fc2 = nn.Linear(80, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.relu(self.conv11(x))\n",
    "        out = self.relu(self.conv12(out))\n",
    "        out = self.relu(self.conv13(out))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.relu(self.conv20(out))\n",
    "        out = self.relu(self.conv21(out))\n",
    "        out = self.relu(self.conv22(out))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "id": "_Uu6LCZLwwsL",
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:10.289276Z",
     "start_time": "2024-02-29T19:14:10.281782Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our face recognition function below first uses our face detection algorithm (Viola-Jones) to decide if a face is found or not. If found, it passes the image through our trained CNN, to try to predict the identity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "best_model_path = './best_model/'\n",
    "model_weights = 'VGGSimple5_95_acc.ckpt'\n",
    "our_model = VGGSimple5(num_classes=81)\n",
    "\n",
    "our_model.load_state_dict(torch.load(best_model_path + model_weights, map_location=torch.device('cpu')))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "our_model.eval()\n",
    "our_model.to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# transformations for normalizing input\n",
    "tr = tf.Compose([\n",
    "    tf.Resize((224, 224)),\n",
    "    tf.ToTensor(),\n",
    "    tf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# labels dictionary\n",
    "with open(best_model_path + \"label_dicts.pk\", \"rb\") as f:\n",
    "  labels_dict = pickle.load(f)\n",
    "\n",
    "labels_to_number = labels_dict[\"labels_to_number\"]\n",
    "number_to_labels = labels_dict[\"number_to_labels\"]\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "SOFTMAX_THRESHOLD = 0.8\n",
    "\n",
    "def my_face_recognition_function(A):\n",
    "    image = face_detection(A, scaleFactor=1.1, minNeighbors=6, minSize=[50, 50])\n",
    "\n",
    "    if image is None:\n",
    "        return -1\n",
    "\n",
    "    image = Image.fromarray(image).convert('RGB')\n",
    "\n",
    "    # Apply the preprocessing\n",
    "    image = tr(image)\n",
    "    image = image.view(1, *image.shape)\n",
    "    image = image.to(device)\n",
    "\n",
    "    predicted_values = softmax(our_model(image)).tolist()[0]\n",
    "    \n",
    "    # filter cases where the predicted class has a low probability\n",
    "    max_softmax = max(predicted_values)\n",
    "    if max_softmax < SOFTMAX_THRESHOLD:\n",
    "        return -1\n",
    "    \n",
    "    predicted_label = int(number_to_labels[predicted_values.index(max_softmax)])\n",
    "\n",
    "    return predicted_label\n"
   ],
   "metadata": {
    "id": "QavRM0Lj1ulb",
    "executionInfo": {
     "status": "error",
     "timestamp": 1708210706701,
     "user_tz": -60,
     "elapsed": 19,
     "user": {
      "displayName": "MANUEL FÉLIX PARMA",
      "userId": "06179278285013016664"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "outputId": "033f4e96-4880-4846-e254-6739bf9b1edb",
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:12.156762Z",
     "start_time": "2024-02-29T19:14:10.291437Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 996017\n"
     ]
    }
   ],
   "source": [
    "# count the parameters of the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model parameters: {count_parameters(our_model)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:12.162709Z",
     "start_time": "2024-02-29T19:14:12.158222Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# predict an example\n",
    "img = imread('./TRAINING_ORIGINAL/image_A0032.jpg')\n",
    "print(my_face_recognition_function(img))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:13.806932Z",
     "start_time": "2024-02-29T19:14:12.163962Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    " Basic script for Face Recognition Challenge\n",
    " --------------------------------------------------------------------\n",
    "AGC Challenge\n",
    "Universitat Pompeu Fabra"
   ],
   "metadata": {
    "id": "_kKk0dBA7FF_"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load challenge Training data\n",
    "AGC_Challenge3_TRAINING = loadmat(\"AGC_Challenge3_Training.mat\")\n",
    "AGC_Challenge3_TRAINING = np.squeeze(AGC_Challenge3_TRAINING['AGC_Challenge3_TRAINING'])\n",
    "\n",
    "imageName = AGC_Challenge3_TRAINING['imageName']\n",
    "imageName = list(itertools.chain.from_iterable(imageName))\n",
    "\n",
    "ids = list(AGC_Challenge3_TRAINING['id'])\n",
    "ids = np.concatenate(ids).ravel().tolist()\n",
    "\n",
    "faceBox = AGC_Challenge3_TRAINING['faceBox']\n",
    "faceBox = list(itertools.chain.from_iterable(faceBox))\n",
    "\n",
    "imgPath = \"./TRAINING_ORIGINAL/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T19:14:13.829948Z",
     "start_time": "2024-02-29T19:14:13.808083Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen 100 images\n",
      "Seen 200 images\n",
      "Seen 300 images\n",
      "Seen 400 images\n",
      "Seen 500 images\n",
      "Seen 600 images\n",
      "Seen 700 images\n",
      "Seen 800 images\n",
      "Seen 900 images\n",
      "Seen 1000 images\n",
      "Seen 1100 images\n",
      "Seen 1200 images\n",
      "F1-score: 83.64, Total time:  0 m 48.61 s\n"
     ]
    }
   ],
   "source": [
    "# Initialize results structure\n",
    "AutoRecognSTR = []\n",
    "\n",
    "# Initialize timer accumulator\n",
    "total_time = 0\n",
    "\n",
    "# Load your FRModel\n",
    "# my_FRmodel = \" \"\n",
    "\n",
    "for idx, im in enumerate(imageName):\n",
    "\n",
    "    if (idx + 1) % 100 == 0:\n",
    "      print(f\"Seen {idx + 1} images\")\n",
    "\n",
    "    A = imread(imgPath + im)\n",
    "\n",
    "    try:\n",
    "        ti = time.time()\n",
    "        # Timer on\n",
    "        ###############################################################\n",
    "        # Your face recognition function goes here.It must accept 2 input parameters:\n",
    "\n",
    "        # 1. the input image A\n",
    "        # 2. the recognition model\n",
    "\n",
    "        # and must return a single integer number as output, which can be:\n",
    "\n",
    "        # a) A number between 1 and 80 (representing one of the identities in the training set)\n",
    "        # b) A \"-1\" indicating that none of the 80 users is present in the input image\n",
    "\n",
    "        autom_id = my_face_recognition_function(A)\n",
    "        \n",
    "        tt = time.time() - ti\n",
    "        total_time = total_time + tt\n",
    "    except:\n",
    "        # If the face recognition function fails, it will be assumed that no user was detected for his input image\n",
    "        autom_id = random.randint(-1, 80)\n",
    "\n",
    "    AutoRecognSTR.append(autom_id)\n",
    "\n",
    "FR_score = CHALL_AGC_ComputeRecognScores(AutoRecognSTR, ids)\n",
    "_, rem = divmod(total_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print('F1-score: %.2f, Total time: %2d m %.2f s' % (100 * FR_score, int(minutes), seconds))"
   ],
   "metadata": {
    "id": "lnZUfsFm6_YG",
    "ExecuteTime": {
     "end_time": "2024-02-29T19:15:07.625188Z",
     "start_time": "2024-02-29T19:14:13.832544Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives: 32\n",
      "False negatives: 88\n",
      "Wrong class: 24\n",
      "Total wrong: 144\n"
     ]
    }
   ],
   "source": [
    "# this small loop gives us an idea of cases to improve\n",
    "np.set_printoptions(suppress=True)\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "wrong_class = 0\n",
    "for real_id, pred_id in zip(ids, AutoRecognSTR):\n",
    "    if real_id != pred_id:\n",
    "        if real_id == -1:\n",
    "            false_positives += 1\n",
    "        elif pred_id == -1:\n",
    "            false_negatives += 1\n",
    "        else:\n",
    "            wrong_class += 1\n",
    "    \n",
    "print(\"False positives:\", false_positives)\n",
    "print(\"False negatives:\", false_negatives)\n",
    "print(\"Wrong class:\", wrong_class)\n",
    "print(\"Total wrong:\", false_positives + false_negatives + wrong_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T19:15:07.630913Z",
     "start_time": "2024-02-29T19:15:07.626531Z"
    }
   },
   "execution_count": 11
  }
 ]
}
